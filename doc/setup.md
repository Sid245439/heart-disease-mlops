# Setup & Reproducibility

This page describes how to set up the project from a clean machine and reproduce results.

## Option A (recommended): `uv` + `nox`

This is the same tooling used by GitHub Actions workflows.

### 1. Install uv

Follow: https://docs.astral.sh/uv/

```bash
pip install uv
```

### 2. Install nox

```bash
uv pip install --system nox nox-uv
```

### 3. Set up development environment

```bash
uv nox -s dev
```

### 4. Run quality gates (format/lint/typing/tests)

```bash
nox
```

Artifacts are written to:

- `doc/reports/ruff/`
- `doc/reports/format/`
- `doc/reports/typing/`
- `doc/reports/pytest/`
- `doc/reports/coverage/`

### 5. Download data + train

```bash
nox -s train
```

Outputs:

- Raw data: `data/raw/heart_disease_raw.csv`
- Model: `models/best_model.pkl`
- Preprocessor: `models/preprocessor.pkl`
- MLflow runs: `mlruns/`

## Option B: pip/venv + requirements.txt

The Docker image installs dependencies from `requirements.txt` (generated via `uv export`).

```bash
python -m venv .venv
. .venv/bin/activate  # macOS/Linux
# Windows PowerShell: .venv\Scripts\Activate.ps1

pip install -r requirements.txt
python download.py
python -c "from src.training import train_pipeline; train_pipeline('data/raw/heart_disease_raw.csv')"
```

## Option C: Conda (legacy / notebook-friendly)

A Conda environment is provided via `environment.yml`.

```bash
conda env create -f environment.yml
conda activate heart-disease-mlops
python download.py
pytest tests/ -v
```

## Reproducibility notes

- Training is deterministic where feasible (`random_state=42`).
- The preprocessor is saved separately and applied during inference to prevent training/serving skew.
- `requirements.txt` is a lock-style export (pinned versions + hashes) generated by `nox -s requirements`.
