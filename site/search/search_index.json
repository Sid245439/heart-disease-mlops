{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"Heart Disease MLOps \u2014 Assignment Documentation","text":"<p>This repository implements an end-to-end MLOps workflow for a Heart Disease risk classifier using the UCI Heart Disease dataset.</p> <p>It is structured to satisfy the assignment requirements:</p> <ul> <li>Data acquisition + EDA</li> <li>Feature engineering + training of at least two models</li> <li>Experiment tracking (MLflow)</li> <li>Reproducible packaging (saved preprocessor + model, requirements)</li> <li>CI with lint/format/typing/tests + artifacts</li> <li>Containerized model-serving API (FastAPI)</li> <li>Kubernetes deployment manifest</li> <li>Monitoring via Prometheus metrics + structured logging</li> </ul>"},{"location":"index.html#quickstart","title":"Quickstart","text":""},{"location":"index.html#run-ci-sessions-locally-same-as-github-actions","title":"Run CI sessions locally (same as GitHub Actions)","text":"<pre><code>uv pip install --system nox nox-uv\nnox\n</code></pre>"},{"location":"index.html#train-models-also-logs-to-mlflow","title":"Train models (also logs to MLflow)","text":"<pre><code>nox -s train\n</code></pre>"},{"location":"index.html#run-api-locally","title":"Run API locally","text":"<pre><code>uvicorn app:app --reload\n</code></pre> <ul> <li>Swagger UI: http://localhost:8000/docs</li> <li>Metrics: http://localhost:8000/metrics</li> </ul>"},{"location":"index.html#assignment-pages","title":"Assignment pages","text":"<ul> <li>Setup &amp; Reproducibility</li> <li>EDA</li> <li>Modeling</li> <li>Experiment Tracking</li> <li>API Serving</li> <li>CI/CD</li> <li>Containerization</li> <li>Deployment (Kubernetes)</li> <li>Monitoring &amp; Logging</li> <li>Architecture</li> <li>Rubric Mapping</li> </ul>"},{"location":"index.html#reports-assets","title":"Reports &amp; assets","text":""},{"location":"index.html#eda-figures","title":"EDA figures","text":"<ul> <li>Target distribution</li> <li>Correlation heatmap</li> <li>Categorical distributions</li> <li>Numerical distributions</li> <li>Confusion matrix</li> </ul>"},{"location":"index.html#monitoring-screenshots","title":"Monitoring screenshots","text":"<ul> <li>Prometheus targets</li> <li>Requests total</li> <li>Request rate v1</li> <li>Request rate v2</li> <li>/metrics output</li> <li>API health curl</li> </ul>"},{"location":"index.html#ci-reports-generated-by-nox-sessions","title":"CI reports (generated by nox sessions)","text":"<ul> <li>Ruff lint report: HTML | JUnit XML</li> <li>Format check report: HTML | Diff patch</li> <li>Mypy report: HTML | JUnit XML</li> <li>Pytest report: HTML | JUnit XML</li> <li>Coverage report: HTML index | XML</li> </ul>"},{"location":"index.html#other-assets","title":"Other assets","text":"<ul> <li>MkDocs static styling: <code>_static/</code></li> </ul>"},{"location":"api.html","title":"API Serving (FastAPI)","text":"<p>The inference service is implemented in <code>app.py</code>.</p>"},{"location":"api.html#endpoints","title":"Endpoints","text":"<ul> <li><code>GET /health</code></li> <li>Returns service status and whether the model is loaded.</li> <li><code>POST /predict</code></li> <li>Accepts a JSON payload matching the <code>PatientData</code> schema.</li> <li>Returns <code>prediction</code>, <code>confidence</code>, and <code>risk_level</code>.</li> <li><code>GET /metrics</code></li> <li>Prometheus metrics endpoint (request counts and latency histogram).</li> </ul>"},{"location":"api.html#run-locally-dev","title":"Run locally (dev)","text":"<pre><code>uvicorn app:app --reload\n</code></pre> <p>Open:</p> <ul> <li>Swagger UI: http://localhost:8000/docs</li> <li>Health: http://localhost:8000/health</li> <li>Metrics: http://localhost:8000/metrics</li> </ul>"},{"location":"api.html#sample-request","title":"Sample request","text":"<pre><code>{\n  \"age\": 63,\n  \"sex\": 1,\n  \"cp\": 3,\n  \"trestbps\": 145,\n  \"chol\": 233,\n  \"fbs\": 1,\n  \"restecg\": 0,\n  \"thalach\": 150,\n  \"exang\": 0,\n  \"oldpeak\": 2.3,\n  \"slope\": 0,\n  \"ca\": 0,\n  \"thal\": 1\n}\n</code></pre>"},{"location":"api.html#logging","title":"Logging","text":"<ul> <li>The service uses Loguru.</li> <li>Logs are written to <code>logs/api.log</code> and also printed to stdout.</li> <li>Control verbosity with <code>LOG_LEVEL</code> (e.g., <code>INFO</code>, <code>DEBUG</code>).</li> </ul>"},{"location":"api.html#model-artifacts","title":"Model artifacts","text":"<p>On startup, the app loads:</p> <ul> <li><code>models/best_model.pkl</code></li> <li><code>models/preprocessor.pkl</code></li> </ul> <p>Make sure you have trained at least once (<code>nox -s train</code>) before starting the service, or build a Docker image after training (so the <code>models/</code> folder is present in the image).</p>"},{"location":"architecture.html","title":"Architecture","text":""},{"location":"architecture.html#high-level-flow","title":"High-level flow","text":"<pre><code>flowchart TD\n  A[UCI Dataset CSV] --&gt; B[download.py]\n  B --&gt; C[data/raw/heart_disease_raw.csv]\n  C --&gt; D[Preprocessing&lt;br/&gt;HeartDiseasePreprocessor]\n  D --&gt; E[Training&lt;br/&gt;Logistic Regression + Random Forest]\n  E --&gt; F[MLflow Tracking&lt;br/&gt;params/metrics/artifacts/models]\n  E --&gt; G[Saved Artifacts&lt;br/&gt;models/best_model.pkl&lt;br/&gt;models/preprocessor.pkl]\n  G --&gt; H[FastAPI Service&lt;br/&gt;app.py]\n  H --&gt; I[\"/predict\"]\n  H --&gt; J[\"/health\"]\n  H --&gt; K[\"/metrics\"]\n  K --&gt; L[Prometheus/Grafana]\n</code></pre>"},{"location":"architecture.html#components","title":"Components","text":"<ul> <li>Data acquisition: <code>download.py</code></li> <li>Preprocessing: <code>src/preprocessing.py</code> (fit/transform, NaN safety, consistent column ordering)</li> <li>Training: <code>src/training.py</code></li> <li>Grid search + cross-validation</li> <li>Logs to MLflow</li> <li>Saves final artifacts to <code>models/</code></li> <li>Serving: <code>app.py</code> (FastAPI)</li> <li>Monitoring: Prometheus scrape config in <code>monitoring/prometheus.yml</code></li> <li>Deployment: Kubernetes manifest in <code>k8s/deployment.yaml</code></li> <li>Automation: <code>noxfile.py</code> + GitHub Actions workflows</li> </ul>"},{"location":"assignment-mapping.html","title":"Rubric Mapping","text":"<p>This page maps the repository contents to the assignment requirements.</p>"},{"location":"assignment-mapping.html#1-data-acquisition-eda","title":"1. Data Acquisition &amp; EDA","text":"<ul> <li>Dataset: UCI Heart Disease CSV</li> <li>Download script: <code>download.py</code> \u2192 saves <code>data/raw/heart_disease_raw.csv</code></li> <li>EDA notebook: <code>exploration/eda.ipynb</code></li> <li>EDA writeup: <code>doc/eda.md</code></li> <li>EDA figures (view in GitHub Pages):</li> <li>Target distribution</li> <li>Correlation heatmap</li> <li>Categorical distributions</li> <li>Numerical distributions</li> </ul>"},{"location":"assignment-mapping.html#2-feature-engineering-model-development","title":"2. Feature Engineering &amp; Model Development","text":"<ul> <li>Preprocessing: <code>src/preprocessing.py</code></li> <li>Missing value handling</li> <li>Encoding</li> <li>Scaling</li> <li>Reproducible transform at inference</li> <li>Two models trained: <code>src/training.py</code></li> <li>Logistic Regression</li> <li>Random Forest</li> <li>Evaluation: accuracy/precision/recall/F1/ROC-AUC + cross-validated tuning (GridSearchCV)</li> <li>Modeling writeup: <code>doc/modeling.md</code></li> </ul>"},{"location":"assignment-mapping.html#3-experiment-tracking","title":"3. Experiment Tracking","text":"<ul> <li>Tool: MLflow</li> <li>Implementation: <code>src/training.py</code></li> <li>Logs params + metrics</li> <li>Logs feature importance plot as artifact</li> <li>Logs models via <code>mlflow.sklearn.log_model</code></li> <li>Guide: <code>doc/experiment-tracking.md</code></li> </ul>"},{"location":"assignment-mapping.html#4-model-packaging-reproducibility","title":"4. Model Packaging &amp; Reproducibility","text":"<ul> <li>Saved artifacts:</li> <li><code>models/best_model.pkl</code></li> <li><code>models/preprocessor.pkl</code></li> <li>Reproducible dependencies:</li> <li><code>requirements.txt</code> (generated via <code>nox -s requirements</code>)</li> <li><code>pyproject.toml</code> + <code>uv.lock</code></li> <li>Reproducibility guide: <code>doc/setup.md</code></li> </ul>"},{"location":"assignment-mapping.html#5-cicd-pipeline-automated-testing","title":"5. CI/CD Pipeline &amp; Automated Testing","text":"<ul> <li>Tests: <code>tests/</code> (Pytest)</li> <li>CI tool: GitHub Actions + Nox</li> <li>Workflows:</li> <li><code>.github/workflows/ci.yml</code> (lint/format/typing/test in parallel)</li> <li><code>.github/workflows/ci-cd.yml</code> (reuses CI + builds Docker + trains)</li> <li>Reports/artifacts (view in GitHub Pages):</li> <li>Ruff lint report: reports/ruff/ruff-lint-report.html</li> <li>Format check report: reports/format/ruff-format-report.html</li> <li>Mypy report: reports/typing/mypy-report.html</li> <li>Pytest report: reports/pytest/pytest-report.html</li> <li>Coverage report: reports/coverage/htmlcov/index.html</li> <li>CI/CD guide: <code>doc/ci-cd.md</code></li> </ul>"},{"location":"assignment-mapping.html#6-model-containerization","title":"6. Model Containerization","text":"<ul> <li>Dockerfile: <code>Dockerfile</code></li> <li>FastAPI API:</li> <li><code>/predict</code> accepts JSON</li> <li>returns prediction + confidence</li> <li>Guide: <code>doc/containerization.md</code></li> </ul>"},{"location":"assignment-mapping.html#7-production-deployment","title":"7. Production Deployment","text":"<ul> <li>Kubernetes manifest: <code>k8s/deployment.yaml</code></li> <li>Deployment + Service + HPA</li> <li>Prometheus scrape annotations</li> <li>Guide: <code>doc/deployment.md</code></li> </ul>"},{"location":"assignment-mapping.html#8-monitoring-logging","title":"8. Monitoring &amp; Logging","text":"<ul> <li>Logging: Loguru \u2192 <code>logs/api.log</code></li> <li>Metrics: Prometheus format at <code>/metrics</code></li> <li>Prometheus config: <code>monitoring/prometheus.yml</code></li> <li>Guide: <code>doc/monitoring.md</code></li> </ul> <p>Monitoring evidence (view in GitHub Pages):</p> <ul> <li>Prometheus targets</li> <li>Requests total</li> <li>Request rate v1</li> <li>Request rate v2</li> <li>/metrics output</li> </ul>"},{"location":"assignment-mapping.html#9-documentation-reporting","title":"9. Documentation &amp; Reporting","text":"<ul> <li>Repo README: <code>README.md</code></li> <li>MkDocs site source: <code>doc/</code></li> <li>Report text: <code>REPORT.md</code> (summary report content)</li> </ul>"},{"location":"ci-cd.html","title":"CI/CD","text":"<p>This project uses <code>nox</code> + <code>uv</code> locally and in GitHub Actions.</p>"},{"location":"ci-cd.html#nox-sessions","title":"Nox sessions","text":"<p>Defined in <code>noxfile.py</code>:</p> <ul> <li><code>nox -s lint</code> \u2013 <code>ruff check</code> (generates JUnit XML + HTML report)</li> <li><code>nox -s format</code> \u2013 <code>ruff format --check --diff</code> (diff patch under <code>doc/reports/format/</code>)</li> <li><code>nox -s typing</code> \u2013 <code>mypy</code> (generates JUnit XML + HTML report)</li> <li><code>nox -s test</code> \u2013 <code>pytest</code> + coverage (JUnit XML + HTML, coverage XML + HTML)</li> <li><code>nox -s train</code> \u2013 downloads data + trains models</li> <li><code>nox -s requirements</code> \u2013 regenerates <code>requirements.txt</code> via <code>uv export</code></li> <li><code>nox -s docs</code> \u2013 builds MkDocs site</li> </ul>"},{"location":"ci-cd.html#github-actions-workflows","title":"GitHub Actions workflows","text":"<p>Workflows are located under <code>.github/workflows/</code>.</p>"},{"location":"ci-cd.html#ci-ciyml","title":"CI (<code>ci.yml</code>)","text":"<p>Runs in parallel jobs:</p> <ul> <li><code>lint</code></li> <li><code>format</code></li> <li><code>typing</code></li> <li><code>test</code></li> </ul> <p>Each job uploads artifacts from <code>doc/reports/</code> so you can view reports per workflow run.</p>"},{"location":"ci-cd.html#cicd-ci-cdyml","title":"CI/CD (<code>ci-cd.yml</code>)","text":"<p>Orchestrates:</p> <ol> <li>Reuses CI via <code>uses: ./.github/workflows/ci.yml</code></li> <li>Builds Docker image (after regenerating <code>requirements.txt</code>)</li> <li>Triggers training via <code>nox -s train</code> and uploads the <code>models/</code> folder as an artifact</li> <li>Runs a security scan (Trivy)</li> </ol>"},{"location":"ci-cd.html#docs-docsyml","title":"Docs (<code>docs.yml</code>)","text":"<ul> <li>Builds MkDocs site via <code>nox -s docs</code></li> <li>Deploys to GitHub Pages (on push to main/master)</li> </ul>"},{"location":"ci-cd.html#where-reports-are-stored","title":"Where reports are stored","text":""},{"location":"ci-cd.html#view-reports-github-pages","title":"View reports (GitHub Pages)","text":"<p>These files live under <code>doc/reports/</code> and are included in the published site, so you can open them directly:</p> <ul> <li>Ruff lint report: reports/ruff/ruff-lint-report.html</li> <li>Format check report: reports/format/ruff-format-report.html</li> <li>Ruff format diff patch: reports/format/ruff-format-diff.patch</li> <li>Black diff patch: reports/format/black-diff.patch</li> <li>Mypy report: reports/typing/mypy-report.html</li> <li>Pytest report: reports/pytest/pytest-report.html</li> <li>Coverage report: reports/coverage/htmlcov/index.html</li> </ul>"},{"location":"ci-cd.html#report-locations-repo-paths","title":"Report locations (repo paths)","text":"<ul> <li>Ruff: <code>doc/reports/ruff/</code></li> <li>Format: <code>doc/reports/format/</code></li> <li>Mypy: <code>doc/reports/typing/</code></li> <li>Pytest: <code>doc/reports/pytest/</code></li> <li>Coverage: <code>doc/reports/coverage/htmlcov/</code></li> </ul>"},{"location":"containerization.html","title":"Containerization (Docker)","text":"<p>The service is containerized using the root <code>Dockerfile</code>.</p>"},{"location":"containerization.html#build","title":"Build","text":"<p>For a fully working image, train first (so <code>models/</code> exists), then build.</p> <pre><code>nox -s train\n\ndocker build -t heart-disease-mlops:latest .\n</code></pre>"},{"location":"containerization.html#run","title":"Run","text":"<pre><code>docker run -p 8000:8000 heart-disease-mlops:latest\n</code></pre> <p>Open:</p> <ul> <li>http://localhost:8000/docs</li> <li>http://localhost:8000/health</li> <li>http://localhost:8000/metrics</li> </ul>"},{"location":"containerization.html#optional-mount-external-model-artifacts","title":"Optional: mount external model artifacts","text":"<p>If you want to rebuild models without rebuilding the image, you can mount <code>models/</code> into the container.</p> <p>PowerShell:</p> <pre><code>docker run -p 8000:8000 -v ${PWD}/models:/app/models:ro heart-disease-mlops:latest\n</code></pre>"},{"location":"containerization.html#notes","title":"Notes","text":"<ul> <li>Dependencies are installed from <code>requirements.txt</code> (generated via <code>nox -s requirements</code>).</li> <li>The container runs Uvicorn on port 8000.</li> </ul>"},{"location":"deployment.html","title":"Production Deployment (Kubernetes)","text":"<p>A Kubernetes manifest is provided at <code>k8s/deployment.yaml</code>.</p>"},{"location":"deployment.html#what-is-deployed","title":"What is deployed","text":"<ul> <li>Deployment: <code>heart-disease-predictor</code> (2 replicas)</li> <li>Service: <code>heart-disease-service</code> (type: <code>LoadBalancer</code>)</li> <li>HPA: <code>heart-disease-hpa</code> (CPU/memory based)</li> </ul> <p>The Pod template includes Prometheus scrape annotations for <code>/metrics</code>.</p>"},{"location":"deployment.html#important-model-artifacts-in-kubernetes","title":"Important: model artifacts in Kubernetes","text":"<p>The API loads these files at startup:</p> <ul> <li><code>models/best_model.pkl</code></li> <li><code>models/preprocessor.pkl</code></li> </ul> <p>The simplest approach for this assignment is:</p> <ol> <li>Train locally: <code>nox -s train</code></li> <li>Build the image after training (so the <code>models/</code> directory is baked into the image).</li> </ol> <p>The current manifest does not mount an external volume at <code>/app/models</code> so that the baked-in model artifacts remain available.</p>"},{"location":"deployment.html#deploy-minikube-docker-desktop-kubernetes","title":"Deploy (Minikube / Docker Desktop Kubernetes)","text":""},{"location":"deployment.html#1-build-the-image","title":"1. Build the image","text":"<pre><code>nox -s train\n\ndocker build -t heart-disease-mlops:latest .\n</code></pre>"},{"location":"deployment.html#2-ensure-the-cluster-can-see-the-image","title":"2. Ensure the cluster can see the image","text":"<ul> <li>Minikube (example):</li> </ul> <pre><code>minikube image load heart-disease-mlops:latest\n</code></pre> <p>Or build directly inside minikube\u2019s Docker daemon.</p>"},{"location":"deployment.html#3-apply-the-manifest","title":"3. Apply the manifest","text":"<pre><code>kubectl apply -f k8s/deployment.yaml\n</code></pre>"},{"location":"deployment.html#4-verify","title":"4. Verify","text":"<pre><code>kubectl get pods -l app=heart-disease\nkubectl get svc heart-disease-service\n</code></pre>"},{"location":"deployment.html#5-access-the-service","title":"5. Access the service","text":"<p>If you don\u2019t have a cloud load balancer (typical for local clusters), use port-forward:</p> <pre><code>kubectl port-forward svc/heart-disease-service 8000:8000\n</code></pre> <p>Then open:</p> <ul> <li>http://localhost:8000/docs</li> </ul>"},{"location":"deployment.html#what-to-screenshot-for-the-report","title":"What to screenshot for the report","text":"<ul> <li><code>kubectl get pods</code> showing READY pods</li> <li><code>kubectl get svc</code> showing service exposure</li> <li>A successful <code>/health</code> and <code>/predict</code> call</li> <li>(Optional) HPA status</li> </ul>"},{"location":"eda.html","title":"Exploratory Data Analysis (EDA) \u2014 Heart Disease UCI","text":"<p>This document captures the complete EDA process used in this project.</p> <p>Primary EDA source:</p> <ul> <li>Notebook: <code>exploration/eda.ipynb</code></li> <li>Generated figures: <code>doc/images/</code></li> </ul>"},{"location":"eda.html#1-objective-and-approach","title":"1. Objective and Approach","text":"<p>Goal: Understand the Heart Disease UCI dataset\u2019s structure, target definition, missingness, feature distributions, and relationships so we can design a robust preprocessing + modeling pipeline.</p> <p>Key EDA outputs (as required):</p> <ul> <li>Target/class balance visualization</li> <li>Feature distribution plots (categorical and numerical)</li> <li>Correlation heatmap</li> <li>Basic statistical association check for categorical features</li> </ul>"},{"location":"eda.html#2-dataset-acquisition","title":"2. Dataset Acquisition","text":"<p>Two equivalent ways are supported in this repo:</p> <ol> <li> <p>Reproducible download script (recommended for pipelines):</p> </li> <li> <p>Script: <code>download.py</code></p> </li> <li>Output: <code>data/raw/heart_disease_raw.csv</code></li> </ol> <p>Run:</p> <pre><code>python download.py\n</code></pre> <p>This script downloads the data from the url <code>https://archive.ics.uci.edu/static/public/45/data.csv</code>. This is the 45th version of the data.</p> <ol> <li>Direct CSV read (used inside the EDA notebook):</li> </ol> <p>The notebook loads from:</p> <ul> <li>https://archive.ics.uci.edu/static/public/45/data.csv</li> </ul>"},{"location":"eda.html#3-data-description-features-target","title":"3. Data Description (Features + Target)","text":"<p>The dataset contains the commonly used 14 attributes (UCI Heart Disease):</p> <ul> <li><code>age</code>: age (years)</li> <li><code>sex</code>: 1=male, 0=female</li> <li><code>cp</code>: chest pain type (1\u20134)</li> <li><code>trestbps</code>: resting blood pressure (mm Hg)</li> <li><code>chol</code>: serum cholesterol (mg/dl)</li> <li><code>fbs</code>: fasting blood sugar &gt; 120 mg/dl (1=true, 0=false)</li> <li><code>restecg</code>: resting ECG results (0\u20132)</li> <li><code>thalach</code>: max heart rate achieved</li> <li><code>exang</code>: exercise induced angina (1=yes, 0=no)</li> <li><code>oldpeak</code>: ST depression induced by exercise relative to rest</li> <li><code>slope</code>: slope of peak exercise ST segment (1\u20133)</li> <li><code>ca</code>: number of major vessels (0\u20133)</li> <li><code>thal</code>: thalassemia indicator (commonly 3, 6, 7)</li> <li><code>num</code>: original diagnosis label (0\u20134)</li> </ul>"},{"location":"eda.html#target-definition-used-in-this-project","title":"Target definition used in this project","text":"<p>The original <code>num</code> is multi-valued (<code>0,1,2,3,4</code>). To make this a binary classification problem:</p> <ul> <li><code>target = 0</code> if <code>num == 0</code> (absence of disease)</li> <li><code>target = 1</code> if <code>num != 0</code> (presence of disease)</li> </ul> <p>After deriving <code>target</code>, the notebook drops <code>num</code> to avoid leakage and ambiguity.</p>"},{"location":"eda.html#4-basic-data-quality-checks","title":"4. Basic Data Quality Checks","text":"<p>The notebook performs initial inspection via:</p> <ul> <li><code>df.info()</code> for dtypes and non-null counts</li> <li><code>df.describe()</code> for numeric summary statistics</li> </ul>"},{"location":"eda.html#missing-values","title":"Missing values","text":"<p>During inspection, two columns stand out as having missing values:</p> <ul> <li><code>ca</code></li> <li><code>thal</code></li> </ul> <p>These are treated as categorical in analysis (even though they are encoded numerically) and are typically handled via mode/most-frequent imputation during preprocessing.</p> <p>Note: for the Chi-square test in the notebook, missing rows are excluded using <code>dropna()</code> to keep the statistical test well-defined.</p>"},{"location":"eda.html#5-class-balance-target-distribution","title":"5. Class Balance (Target Distribution)","text":"<p>To validate the problem setup and understand potential imbalance, the notebook plots a countplot of <code>target</code>.</p> <p></p> <p>Interpretation (as observed in the notebook):</p> <ul> <li>The dataset is not extremely imbalanced, but class proportions should still be verified before choosing metrics and thresholds.</li> </ul>"},{"location":"eda.html#6-feature-type-grouping-for-eda","title":"6. Feature-Type Grouping for EDA","text":"<p>For analysis, features are grouped into categorical vs numerical:</p> <p>Categorical (discrete, encoded) columns:</p> <pre><code>sex, cp, fbs, restecg, exang, slope, ca, thal\n</code></pre> <p>Numerical (continuous/ordinal) columns:</p> <pre><code>age, trestbps, chol, thalach, oldpeak\n</code></pre> <p>This grouping drives the choice of plots and informs later preprocessing decisions (encoding and scaling).</p>"},{"location":"eda.html#7-univariate-analysis-distributions","title":"7. Univariate Analysis (Distributions)","text":""},{"location":"eda.html#71-categorical-feature-distributions-by-target","title":"7.1 Categorical feature distributions by target","text":"<p>The notebook generates countplots for each categorical feature with <code>hue=\"target\"</code> to compare category frequencies across the two classes.</p> <p></p> <p>Typical EDA takeaways from these plots:</p> <ul> <li>Some categorical features show visibly different distributions between <code>target=0</code> and <code>target=1</code>, which suggests predictive signal.</li> <li>Some categories are dominant within a feature (rare categories exist), which is important for encoding choices and potential regularization.</li> </ul>"},{"location":"eda.html#72-numerical-feature-distributions-by-target","title":"7.2 Numerical feature distributions by target","text":"<p>The notebook uses histogram + KDE overlays (<code>sns.histplot(..., kde=True)</code>) split by target.</p> <p></p> <p>Notebook observation captured in comments:</p> <ul> <li>Most numerical variables appear roughly bell-shaped except <code>oldpeak</code>, which is more skewed.</li> </ul> <p>Implication for modeling (preprocessing decision driver):</p> <ul> <li>Standardization is generally suitable for most continuous features.</li> <li>Skewed features can sometimes benefit from alternative scaling (e.g., MinMax/robust scaling) or transformations, to be validated during model development.</li> </ul>"},{"location":"eda.html#8-correlation-analysis","title":"8. Correlation Analysis","text":"<p>To identify linear relationships and potential multicollinearity, the notebook computes a correlation matrix and visualizes it using a heatmap (values shown as percentages).</p> <p></p> <p>Notebook conclusion:</p> <ul> <li>No pair of features exhibits extremely high correlation that would force removal purely due to multicollinearity concerns.</li> <li>Therefore, all features are retained for downstream model training (feature selection is deferred to modeling/validation).</li> </ul>"},{"location":"eda.html#9-statistical-association-for-categorical-features-chi-square-test","title":"9. Statistical Association for Categorical Features (Chi-square Test)","text":"<p>To quantify whether categorical features are associated with the target, the notebook runs a Chi-square test (<code>sklearn.feature_selection.chi2</code>) on the categorical subset (after dropping missing rows).</p> <p>Result interpretation recorded in the notebook:</p> <ul> <li>Most categorical variables show statistically significant association with the target (p-value &lt; 0.05).</li> <li><code>fbs</code> is not significant in isolation (very high p-value), but is still retained because:</li> <li>features can contribute jointly even if marginal association is weak</li> <li>final decision should be made using cross-validated model performance</li> </ul>"},{"location":"eda.html#10-reproducibility-how-to-regenerate-eda-outputs","title":"10. Reproducibility: How to Regenerate EDA Outputs","text":"<p>From a clean environment:</p> <ol> <li> <p>Run the notebook end-to-end:</p> </li> <li> <p>Open: <code>exploration/eda.ipynb</code></p> </li> <li>Run all cells</li> <li>Figures are saved to: <code>doc/images/</code></li> </ol> <p>Optional: a lightweight script also exists for quick checks:</p> <ul> <li><code>src/eda.py</code> prints basic info and writes plots into <code>logs/</code>.</li> </ul>"},{"location":"eda.html#11-eda-artifacts-for-report-submission","title":"11. EDA Artifacts (for Report / Submission)","text":"<p>The notebook saves the following figures (submission-ready):</p> <ul> <li><code>doc/images/heart_disease_target_distribution.png</code></li> <li><code>doc/images/heart_disease_categorical_distribution.png</code></li> <li><code>doc/images/heart_disease_numerical_distribution.png</code></li> <li><code>doc/images/heart_disease_correlation_matrix.png</code></li> </ul>"},{"location":"experiment-tracking.html","title":"Experiment Tracking","text":""},{"location":"experiment-tracking.html#experiment-tracking-mlflow","title":"Experiment Tracking (MLflow)","text":"<p>This project uses MLflow Tracking to record model-training experiments (parameters, metrics, and artifacts) so you can compare runs and reproduce results.</p>"},{"location":"experiment-tracking.html#what-gets-tracked","title":"What gets tracked","text":"<p>During training, the code in <code>src/training.py</code>:</p> <ul> <li>Sets/uses an MLflow experiment named <code>heart-disease-mlops</code>.</li> <li>Creates runs for:</li> <li>Logistic Regression (<code>run_name=\"logistic-regression\"</code>)</li> <li>Random Forest (<code>run_name=\"random-forest\"</code>)</li> <li>Logs:</li> <li>Params: hyperparameters (e.g., <code>C</code> for LR, <code>n_estimators</code>, <code>max_depth</code> for RF)</li> <li>Metrics: accuracy/precision/recall/F1 + AUC values</li> <li>Artifacts: a feature-importance plot for Random Forest</li> <li>Models: each trained estimator via <code>mlflow.sklearn.log_model(...)</code></li> </ul> <p>In addition to MLflow tracking, the pipeline also writes local model artifacts:</p> <ul> <li><code>models/best_model.pkl</code></li> <li><code>models/preprocessor.pkl</code></li> </ul>"},{"location":"experiment-tracking.html#prerequisites","title":"Prerequisites","text":"<p>You need Python dependencies installed.</p> <p>Recommended (this repo\u2019s standard):</p> <ul> <li>Install <code>uv</code></li> <li>Use <code>nox</code> sessions (which use <code>uv</code> under the hood via <code>nox-uv</code>)</li> </ul> <p>If you haven\u2019t installed <code>nox</code> locally yet:</p> <pre><code>uv pip install --system nox nox-uv\n</code></pre>"},{"location":"experiment-tracking.html#option-a-simplest-track-locally-with-the-default-file-store","title":"Option A (simplest): track locally with the default file store","text":"<p>By default, MLflow stores runs in a local folder named <code>./mlruns</code> (created automatically).</p> <ol> <li>Run training</li> </ol> <pre><code>nox -s train\n</code></pre> <p>This downloads the dataset (to <code>data/raw/heart_disease_raw.csv</code>) and runs the training pipeline.</p> <ol> <li>Start the MLflow UI</li> </ol> <pre><code>mlflow ui --host localhost --port 5000\n</code></pre> <ol> <li> <p>Open the UI in your browser</p> </li> <li> <p><code>http://localhost:5000</code></p> </li> </ol>"},{"location":"experiment-tracking.html#option-b-run-an-mlflow-tracking-server-recommended-for-repeatable-local-work","title":"Option B: run an MLflow Tracking Server (recommended for repeatable local work)","text":"<p>If you want a more \u201cserver-like\u201d setup (separate backend store + artifact directory), run:</p> <pre><code>mlflow server \\\n    --backend-store-uri sqlite:///mlflow.db \\\n    --default-artifact-root ./mlartifacts \\\n    --host localhost \\\n    --port 5000\n</code></pre> <p>Then, in a separate terminal, point clients at it:</p> <pre><code>export MLFLOW_TRACKING_URI=http://localhost:5000\nnox -s train\n</code></pre> <p>Windows PowerShell:</p> <pre><code>$env:MLFLOW_TRACKING_URI = \"http://localhost:5000\"\nnox -s train\n</code></pre>"},{"location":"experiment-tracking.html#where-to-find-results","title":"Where to find results","text":"<ul> <li>MLflow UI:</li> <li>Experiments \u2192 <code>heart-disease-mlops</code></li> <li>Runs \u2192 compare LR vs RF, metrics, params</li> <li>Artifacts tab \u2192 model artifacts + feature importance plot</li> <li>Local files:</li> <li><code>models/best_model.pkl</code> and <code>models/preprocessor.pkl</code> are used by the inference service.</li> </ul>"},{"location":"experiment-tracking.html#common-troubleshooting","title":"Common troubleshooting","text":"<ul> <li> <p>UI shows no runs</p> </li> <li> <p>Make sure the UI points at the same backend store where runs are written.</p> </li> <li> <p>If you used the default file store, run <code>mlflow ui --backend-store-uri file:./mlruns</code> from the repo root.</p> </li> <li> <p>Port already in use (5000)</p> </li> <li> <p>Pick another port, e.g. <code>--port 5001</code>.</p> </li> <li> <p>Runs are created but artifacts are missing</p> </li> <li> <p>Check file permissions in the artifact root directory.</p> </li> <li> <p>For a server setup, confirm <code>--default-artifact-root</code> is writable.</p> </li> <li> <p>CI vs local behavior</p> </li> <li>In CI, a long-running MLflow server usually isn\u2019t started; tracking typically writes to the local file store.</li> </ul>"},{"location":"modeling.html","title":"Feature Engineering &amp; Model Development","text":"<p>This document describes the complete modeling workflow for the Heart Disease UCI dataset:</p> <ul> <li>Feature engineering (encoding + scaling)</li> <li>Training at least two classification models</li> <li>Documented model selection/tuning</li> <li>Evaluation using appropriate metrics</li> <li>Reproducible pipeline implementation (scripted training)</li> </ul> <p>Primary sources:</p> <ul> <li>Notebook: <code>exploration/modeling.ipynb</code> (model experimentation and threshold analysis)</li> <li>Training pipeline: <code>src/training.py</code> (cross-validated tuning + MLflow logging)</li> <li>Preprocessing utilities: <code>src/preprocessing.py</code></li> </ul>"},{"location":"modeling.html#1-problem-formulation","title":"1. Problem Formulation","text":"<p>Task: binary classification to predict heart disease risk.</p> <p>Target construction (binary):</p> <ul> <li>Original label <code>num</code> is multi-class (0\u20134).</li> <li>Project target uses: <code>target = 1</code> if <code>num != 0</code>, else <code>0</code>.</li> </ul> <p>This aligns with common clinical framing: any positive diagnosis is treated as \u201cdisease present\u201d.</p>"},{"location":"modeling.html#2-feature-set","title":"2. Feature Set","text":"<p>The modeling notebook explicitly selects a 13-feature input set plus the derived target:</p> <p>Categorical (discrete/encoded) features</p> <ul> <li><code>sex</code>, <code>cp</code>, <code>fbs</code>, <code>restecg</code>, <code>exang</code>, <code>slope</code>, <code>ca</code>, <code>thal</code></li> </ul> <p>Numeric features (standard-scaled)</p> <ul> <li><code>age</code>, <code>trestbps</code>, <code>chol</code>, <code>thalach</code></li> </ul> <p>Numeric feature (min-max scaled)</p> <ul> <li><code>oldpeak</code></li> </ul> <p>Rationale (from EDA + common practice): most continuous features are approximately well-behaved under standardization, while <code>oldpeak</code> is often skewed and can benefit from bounded scaling.</p>"},{"location":"modeling.html#3-data-splitting-strategy","title":"3. Data Splitting Strategy","text":"<p>In <code>exploration/modeling.ipynb</code>, the dataset is split into:</p> <ul> <li>Train: 70%</li> <li>Validation: 15%</li> <li>Test: 15%</li> </ul> <p>Important details:</p> <ul> <li><code>stratify</code> is used on the target to preserve class proportions across splits.</li> <li><code>random_state=42</code> ensures repeatability.</li> </ul> <p>Purpose:</p> <ul> <li>Validation set is used to tune decision threshold (see Section 6).</li> <li>Test set is held out for the final unbiased evaluation.</li> </ul>"},{"location":"modeling.html#4-preprocessing-feature-engineering-pipeline","title":"4. Preprocessing / Feature Engineering Pipeline","text":"<p>The notebook uses a fully reproducible <code>sklearn</code> <code>ColumnTransformer</code>:</p>"},{"location":"modeling.html#41-numerical-preprocessing","title":"4.1 Numerical preprocessing","text":"<ul> <li>Missing values imputed with median (<code>SimpleImputer(strategy=\"median\")</code>)</li> <li>Scaling:</li> <li>StandardScaler for <code>age</code>, <code>trestbps</code>, <code>chol</code>, <code>thalach</code></li> <li>MinMaxScaler for <code>oldpeak</code></li> </ul>"},{"location":"modeling.html#42-categorical-preprocessing","title":"4.2 Categorical preprocessing","text":"<ul> <li>Missing values imputed with most frequent (<code>SimpleImputer(strategy=\"most_frequent\")</code>)</li> <li>One-hot encoding via <code>OneHotEncoder(handle_unknown=\"ignore\")</code></li> <li><code>handle_unknown=\"ignore\"</code> is important for robust inference when previously unseen categories appear.</li> </ul>"},{"location":"modeling.html#43-why-a-pipeline-matters-mlops-relevance","title":"4.3 Why a pipeline matters (MLOps relevance)","text":"<p>This design prevents training/serving skew by ensuring that the exact same transformations used during training are applied at inference time.</p>"},{"location":"modeling.html#5-candidate-models-notebook-experimentation","title":"5. Candidate Models (Notebook Experimentation)","text":"<p>The notebook evaluates multiple classifiers under the same preprocessing pipeline:</p> <ul> <li>Logistic Regression (<code>class_weight=\"balanced\"</code>)</li> <li>Random Forest (<code>n_estimators=400</code>, <code>class_weight=\"balanced\"</code>)</li> <li>Histogram-based Gradient Boosting (<code>HistGradientBoostingClassifier</code>)</li> <li>Support Vector Classifier (<code>SVC(class_weight=\"balanced\")</code>)</li> <li>Gaussian Naive Bayes (<code>GaussianNB</code>)</li> <li>XGBoost (<code>XGBClassifier</code>, tuned with a conservative learning rate and many estimators)</li> </ul> <p>All candidates are trained as:</p> <ul> <li><code>Pipeline([(\"prep\", preprocessor), (\"clf\", model)])</code></li> </ul> <p>This ensures a fair comparison with identical preprocessing.</p>"},{"location":"modeling.html#6-threshold-selection-recall-constrained-decision-rule","title":"6. Threshold Selection (Recall-Constrained Decision Rule)","text":"<p>In healthcare-oriented risk prediction, false negatives can be more costly than false positives. The notebook therefore does not rely purely on the default 0.5 threshold.</p> <p>It defines a helper <code>get_best_threshold(...)</code>:</p> <ul> <li>Sweeps thresholds from 0.00 to 1.00</li> <li>Chooses the highest threshold that achieves at least a target recall on validation</li> </ul> <p>Two recall constraints are used in the notebook:</p> <ul> <li>Candidate comparison: <code>min_recall=0.99</code></li> <li>Final Logistic Regression selection: <code>min_recall=0.95</code></li> </ul> <p>This produces a tuned operating point that prioritizes sensitivity (recall), then reports the resulting precision/accuracy/F1.</p> <p>Notes on probability handling:</p> <ul> <li>For models supporting <code>predict_proba</code>, probabilities are used.</li> <li>Otherwise, <code>decision_function</code> is used as a scoring proxy.</li> </ul>"},{"location":"modeling.html#7-evaluation-metrics","title":"7. Evaluation Metrics","text":"<p>The notebook reports standard classification metrics on validation and test:</p> <ul> <li>Accuracy</li> <li>Precision</li> <li>Recall</li> <li>F1-score</li> </ul> <p>Additionally, it visualizes a confusion matrix for the final selected model on the test set.</p> <p></p> <p>Why these metrics:</p> <ul> <li>Accuracy can be misleading when classes are imbalanced.</li> <li>Precision/Recall/F1 provide a better picture of clinical screening tradeoffs.</li> <li>Threshold tuning is explicitly tied to a recall target.</li> </ul>"},{"location":"modeling.html#8-final-model-choice-notebook","title":"8. Final Model Choice (Notebook)","text":"<p>After comparing candidates, the notebook fits a final pipeline with:</p> <ul> <li><code>LogisticRegression(solver=\"liblinear\", max_iter=1000, random_state=42)</code></li> </ul> <p>and evaluates it using the validation-chosen threshold on the test set.</p> <p>Rationale for Logistic Regression (typical justifications consistent with the notebook setup):</p> <ul> <li>Strong baseline for tabular medical data</li> <li>Interpretable and stable</li> <li>Fast training and suitable for CI/CD retraining loops</li> </ul>"},{"location":"modeling.html#9-scripted-reproducible-training-project-pipeline","title":"9. Scripted, Reproducible Training (Project Pipeline)","text":"<p>While the notebook focuses on experimentation and threshold analysis, the production-oriented training flow is implemented in <code>src/training.py</code>.</p>"},{"location":"modeling.html#91-models-trained-assignment-requirement","title":"9.1 Models trained (assignment requirement)","text":"<p>The pipeline trains two required models:</p> <ul> <li>Logistic Regression (with hyperparameter search over <code>C</code>)</li> <li>Random Forest (with hyperparameter search over <code>n_estimators</code>, <code>max_depth</code>, <code>min_samples_split</code>)</li> </ul>"},{"location":"modeling.html#92-cross-validation-and-tuning","title":"9.2 Cross-validation and tuning","text":"<p>Both models are tuned with <code>GridSearchCV</code> using:</p> <ul> <li><code>cv=5</code></li> <li><code>scoring=\"roc_auc\"</code></li> </ul> <p>This meets the assignment requirement to evaluate with cross-validation and a relevant metric (ROC-AUC).</p>"},{"location":"modeling.html#93-metrics-collected","title":"9.3 Metrics collected","text":"<p>The pipeline computes and logs (train + test where applicable):</p> <ul> <li>Accuracy</li> <li>Precision</li> <li>Recall</li> <li>F1</li> <li>ROC-AUC</li> </ul>"},{"location":"modeling.html#94-model-selection","title":"9.4 Model selection","text":"<p>The pipeline selects the best model based on test ROC-AUC.</p>"},{"location":"modeling.html#95-artifacts-saved","title":"9.5 Artifacts saved","text":"<p>The pipeline saves:</p> <ul> <li><code>models/best_model.pkl</code></li> <li><code>models/preprocessor.pkl</code></li> </ul> <p>These are the artifacts loaded by the serving API in <code>app.py</code>.</p>"},{"location":"modeling.html#10-how-to-reproduce-modeling-end-to-end","title":"10. How to Reproduce Modeling End-to-End","text":""},{"location":"modeling.html#option-a-notebook-exploration","title":"Option A \u2014 Notebook exploration","text":"<p>Open and run:</p> <ul> <li><code>exploration/modeling.ipynb</code></li> </ul> <p>This reproduces the preprocessing pipeline, candidate comparison, threshold tuning, and confusion matrix visualization.</p>"},{"location":"modeling.html#option-b-reproducible-training-pipeline-recommended","title":"Option B \u2014 Reproducible training pipeline (recommended)","text":"<ol> <li>Download data:</li> </ol> <pre><code>python download.py\n</code></pre> <ol> <li>Train + log experiments:</li> </ol> <pre><code>python -c \"from src.training import train_pipeline; train_pipeline('data/raw/heart_disease_raw.csv')\"\n</code></pre> <ol> <li>View experiment tracking UI:</li> </ol> <pre><code>mlflow ui --host localhost --port 5000\n</code></pre> <p>This will use the local <code>mlruns/</code> directory and show runs for Logistic Regression and Random Forest (parameters, metrics, and model artifacts).</p>"},{"location":"monitoring.html","title":"Monitoring &amp; Logging","text":""},{"location":"monitoring.html#logging","title":"Logging","text":"<p>The API (<code>app.py</code>) uses Loguru and intercepts standard Python logging so Uvicorn/FastAPI logs are routed consistently.</p> <ul> <li>Log file: <code>logs/api.log</code></li> <li>Configure level: <code>LOG_LEVEL</code> (e.g., <code>INFO</code>, <code>DEBUG</code>)</li> </ul>"},{"location":"monitoring.html#metrics-prometheus","title":"Metrics (Prometheus)","text":"<p>The service exposes Prometheus metrics at:</p> <ul> <li><code>GET /metrics</code></li> </ul> <p>Metrics include:</p> <ul> <li><code>heart_api_requests_total{method,endpoint,http_status}</code></li> <li><code>heart_api_request_latency_seconds_bucket{endpoint,...}</code></li> </ul>"},{"location":"monitoring.html#run-prometheus-locally-docker","title":"Run Prometheus locally (Docker)","text":"<p>A sample scrape config exists at <code>monitoring/prometheus.yml</code>.</p> <pre><code>docker run -p 9090:9090 \\\n  -v $(pwd)/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml \\\n  prom/prometheus\n</code></pre> <p>Windows PowerShell:</p> <pre><code>docker run -p 9090:9090 `\n  -v ${PWD}/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml `\n  prom/prometheus\n</code></pre> <p>Open:</p> <ul> <li>http://localhost:9090</li> </ul> <p>Example queries:</p> <ul> <li>Requests by endpoint:</li> <li><code>sum by (endpoint) (heart_api_requests_total)</code></li> <li>Request rate:</li> <li><code>sum by (endpoint) (rate(heart_api_requests_total[1m]))</code></li> </ul>"},{"location":"monitoring.html#grafana-optional","title":"Grafana (optional)","text":"<pre><code>docker run -d -p 3000:3000 grafana/grafana\n</code></pre> <p>Add a Prometheus datasource:</p> <ul> <li>URL: <code>http://host.docker.internal:9090</code></li> </ul>"},{"location":"monitoring.html#what-to-screenshot-for-the-report","title":"What to screenshot for the report","text":"<ul> <li>Prometheus Targets page showing the API as UP</li> <li>A chart for request rate</li> <li>A chart for request totals</li> <li>API <code>/metrics</code> output in the browser or terminal</li> <li>Sample <code>logs/api.log</code> lines after calling <code>/predict</code></li> </ul>"},{"location":"monitoring.html#included-screenshots-click-to-open","title":"Included screenshots (click to open)","text":"<p>These screenshots are stored in <code>doc/images/screenshots/</code> and published with GitHub Pages.</p>"},{"location":"monitoring.html#prometheus-targets","title":"Prometheus targets","text":"<p>Open image</p> <p></p>"},{"location":"monitoring.html#requests-total","title":"Requests total","text":"<p>Open image</p> <p></p>"},{"location":"monitoring.html#request-rate","title":"Request rate","text":"<p>Open image (v1)</p> <p></p> <p>Open image (v2)</p> <p></p>"},{"location":"monitoring.html#metrics-output","title":"/metrics output","text":"<p>Open image</p> <p></p>"},{"location":"monitoring.html#api-health-proof","title":"API health proof","text":"<p>Open image</p> <p></p>"},{"location":"setup.html","title":"Setup &amp; Reproducibility","text":"<p>This page describes how to set up the project from a clean machine and reproduce results.</p>"},{"location":"setup.html#option-a-recommended-uv-nox","title":"Option A (recommended): <code>uv</code> + <code>nox</code>","text":"<p>This is the same tooling used by GitHub Actions workflows.</p>"},{"location":"setup.html#1-install-uv","title":"1. Install uv","text":"<p>Follow: https://docs.astral.sh/uv/</p> <pre><code>pip install uv\n</code></pre>"},{"location":"setup.html#2-install-nox","title":"2. Install nox","text":"<pre><code>uv pip install --system nox nox-uv\n</code></pre>"},{"location":"setup.html#3-set-up-development-environment","title":"3. Set up development environment","text":"<pre><code>uv nox -s dev\n</code></pre>"},{"location":"setup.html#4-run-quality-gates-formatlinttypingtests","title":"4. Run quality gates (format/lint/typing/tests)","text":"<pre><code>nox\n</code></pre> <p>Artifacts are written to:</p> <ul> <li><code>doc/reports/ruff/</code></li> <li><code>doc/reports/format/</code></li> <li><code>doc/reports/typing/</code></li> <li><code>doc/reports/pytest/</code></li> <li><code>doc/reports/coverage/</code></li> </ul>"},{"location":"setup.html#5-download-data-train","title":"5. Download data + train","text":"<pre><code>nox -s train\n</code></pre> <p>Outputs:</p> <ul> <li>Raw data: <code>data/raw/heart_disease_raw.csv</code></li> <li>Model: <code>models/best_model.pkl</code></li> <li>Preprocessor: <code>models/preprocessor.pkl</code></li> <li>MLflow runs: <code>mlruns/</code></li> </ul>"},{"location":"setup.html#option-b-pipvenv-requirementstxt","title":"Option B: pip/venv + requirements.txt","text":"<p>The Docker image installs dependencies from <code>requirements.txt</code> (generated via <code>uv export</code>).</p> <pre><code>python -m venv .venv\n. .venv/bin/activate  # macOS/Linux\n# Windows PowerShell: .venv\\Scripts\\Activate.ps1\n\npip install -r requirements.txt\npython download.py\npython -c \"from src.training import train_pipeline; train_pipeline('data/raw/heart_disease_raw.csv')\"\n</code></pre>"},{"location":"setup.html#option-c-conda-legacy-notebook-friendly","title":"Option C: Conda (legacy / notebook-friendly)","text":"<p>A Conda environment is provided via <code>environment.yml</code>.</p> <pre><code>conda env create -f environment.yml\nconda activate heart-disease-mlops\npython download.py\npytest tests/ -v\n</code></pre>"},{"location":"setup.html#reproducibility-notes","title":"Reproducibility notes","text":"<ul> <li>Training is deterministic where feasible (<code>random_state=42</code>).</li> <li>The preprocessor is saved separately and applied during inference to prevent training/serving skew.</li> <li><code>requirements.txt</code> is a lock-style export (pinned versions + hashes) generated by <code>nox -s requirements</code>.</li> </ul>"}]}